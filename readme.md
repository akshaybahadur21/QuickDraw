# Quick, Draw ğŸ–Œï¸ &nbsp; ğŸ–¼ï¸
[![](https://img.shields.io/github/license/sourcerer-io/hall-of-fame.svg?colorB=ff0000)](https://github.com/akshaybahadur21/Emojinator/blob/master/LICENSE.md)  [![](https://img.shields.io/badge/Akshay-Bahadur-brightgreen.svg?colorB=ff0000)](https://akshaybahadur.com)

Can a neural network learn to recognize doodling? [Quick, Draw](https://quickdraw.withgoogle.com/)

## Code Requirements ğŸ¦„
You can install Conda for python which resolves all the dependencies for machine learning.

##### pip install -r requirements.txt

## Description ğŸ‘¨â€ğŸ¨
Quick, Draw! is an online game developed by Google that challenges players to draw a picture of an object or idea and then uses a neural network artificial intelligence to guess what the drawings represent. The AI learns from each drawing, increasing its ability to guess correctly in the future.The game is similar to Pictionary in that the player only has a limited time to draw (20 seconds).The concepts that it guesses can be simple, like 'foot', or more complicated, like 'animal migration'. This game is one of many simple games created by Google that are AI based as part of a project known as 'A.I. Experiments'. [Quick, Draw](https://quickdraw.withgoogle.com/)

## Dataset ğŸ—ƒï¸
Follow the documentation [here](https://github.com/googlecreativelab/quickdraw-dataset) to get the dataset. I got `.npy` files from google cloud for 14 drawings.

#### Labels
1) Apple :apple:
2) Bowtie ğŸ€	
3) Candle ğŸ•¯ï¸
4) Door :door:
5) Envelope :envelope:
6) Fish :fish:
6) Guitar :guitar:
7) Ice Cream :icecream:
8) Lightning âš¡
9) Moon :first_quarter_moon_with_face:
10) Mountain :mount_fuji:
11) Star :star:
12) Tent :tent:
13) Toothbrush ğŸ§¹
14) Wristwatch :watch:

## Python  Implementation ğŸ‘¨â€ğŸ”¬

1) Network Used- Convolutional Neural Network

If you face any problem, kindly raise an issue

## Setup ğŸ–¥ï¸

1) Get the dataset as mentioned above and place the `.npy` files in `/data` folder.
2) First, run `LoadData.py` which will load the data from the `/data` folder and store the features and labels in  pickel files.
3) Now you need to have the data, run `QD_trainer.py` which will load data from pickle and augment it. After this, the training process begins.
2) Now you need to have the data, run `QuickDrawApp.py` which will use use the webcam to get what you have drawn.
3) For altering the model, check `QD_trainer.py`.
4) For tensorboard visualization, go to the specific log directory and run this command ` tensorboard --logdir=.` You can go to `localhost:6006` for visualizing your loss function and accuracy.

## Mergerd to Google's git repo ğŸŒ¼

See the pull request [here](https://github.com/googlecreativelab/quickdraw-dataset/pull/25)

## Execution ğŸ‰

```
python3 QuickDrawApp.py
```

## Results ğŸ“Š
<img src="https://github.com/akshaybahadur21/QuickDraw/blob/master/qd.gif">

## References: ğŸ”±
 
 - [Google's Quick, Draw](https://quickdraw.withgoogle.com/) 
 - [The Quick, Draw! Dataset](https://github.com/googlecreativelab/quickdraw-dataset)
 - [Quick Draw: the worldâ€™s largest doodle dataset](https://towardsdatascience.com/quick-draw-the-worlds-largest-doodle-dataset-823c22ffce6b)





